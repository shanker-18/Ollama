# Ollama + LangChain Chatbot (Local LLM Integration)

This project demonstrates a locally running **LLM-powered chatbot** using **Ollama**, **LangChain**, and **Streamlit** — designed for privacy-first, offline-friendly AI interactions without relying on cloud APIs like OpenAI or Anthropic.

---

## Features

- Uses **Ollama** to run LLMs like LLaMA2, Mistral, or Code LLaMA locally
- Powered by **LangChain** for chaining prompts and memory
- Streamlit frontend for user interaction
- Completely private and API-free (no OpenAI key required)

---

## Tech Stack

- Python 3.10+
- [Ollama](https://ollama.com/) – Local LLM backend
- LangChain – Prompt templates, memory, tools
- Streamlit – Frontend interface
- Optional: LLM models like `llama2`, `mistral`, `codellama`, etc.

---


